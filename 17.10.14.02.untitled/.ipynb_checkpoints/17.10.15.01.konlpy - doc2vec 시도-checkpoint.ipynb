{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\", \"malgun gothic\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width: 100%;\n",
       "    }\n",
       "    ul {\n",
       "        line-height: 145%;\n",
       "        font-size: 90%;\n",
       "    }\n",
       "    li {\n",
       "        margin-bottom: 0.2em;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: \"malgun gothic\";\n",
       "    }\n",
       "    code {\n",
       "        font-family: \"malgun gothic\";\n",
       "    }\n",
       "    div.h1 {\n",
       "        font-family: \"malgun gothic\";\n",
       "    }\n",
       "    h4{\n",
       "        margin-top: 12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    pre {\n",
       "        font-family: 'malgun gothic';\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif, \"malgun gothic\";;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width: 90%;\n",
       "//        margin-left:auto;\n",
       "//        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", \"malgun gothic\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mac475의 ipython 표준 style을 적용함\n",
    "from IPython.core.display import HTML\n",
    "styles = open(\"../resources/styles/custom.css\", \"r\").read()\n",
    "HTML( styles )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Pretty Display of Variables를 적용하여 중간 결과를 확인하고자 함\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# matplotlib plot내 한글의 표현위한 설정\n",
    "from matplotlib import font_manager, rc\n",
    "font_fname = 'c:/windows/fonts/malgun.ttf'     # A font of your choice\n",
    "font_name = font_manager.FontProperties(fname=font_fname).get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 영화리뷰 data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data reading function\n",
    "def read_data(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = [line.split('\\t')[1:] for line in f.read().splitlines()]\n",
    "        data = data[1:]   # header 제외\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = read_data('./datasets/ratings_train.txt')\n",
    "test_data = read_data('./datasets/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pos tagger 정의, parts of speech : 품사\n",
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize(doc):\n",
    "    # norm, stem은 optional\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 150000/150000 [03:18<00:00, 757.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_docs = [(tokenize(row[0]), row[1]) for row in tqdm(train_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 50000/50000 [00:58<00:00, 858.50it/s]\n"
     ]
    }
   ],
   "source": [
    "test_docs = [(tokenize(row[0]), row[1]) for row in tqdm(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['아/Exclamation',\n",
       "  '더빙/Noun',\n",
       "  '../Punctuation',\n",
       "  '진짜/Noun',\n",
       "  '짜증/Noun',\n",
       "  '나다/Verb',\n",
       "  '목소리/Noun'],\n",
       " '0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(['굳다/Adjective', 'ㅋ/KoreanParticle'], '1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs[0]\n",
    "test_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2194536"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 document내의 pos tagging된 word를 하나의 list에 tokens로 담는다\n",
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. doc2vec 기반 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc2vec concept\n",
    "\n",
    "- 참고 : https://stackoverflow.com/questions/42827175/gensim-what-is-difference-between-word2vec-and-doc2vec\n",
    "\n",
    "In word2vec, you train to find word vectors and then run similarity queries between words.\n",
    "\n",
    "In doc2vec, you tag your text and you also get tag vectors.\n",
    "\n",
    "For instance, you have different documents from different authors and use authors as tags on documents\n",
    "\n",
    "Then, after doc2vec training you can use the same vector aritmetics to run similarity queries on author tags: i.e who are the most similar authors to AUTHOR_X? If two authors generally use the same words then their vector will be closer. AUTHOR_X is not a real word which is part of your corpus just something you determine. So you don't need to have it or manually insert it into your text. Gensim allows you to train doc2vec with or without word vectors (i.e. if you only care about tag similarities between each other).\n",
    "\n",
    "Here is a good presentation (https://www.youtube.com/watch?v=vkfXBGnDplQ) on word2vec basics and how they use doc2vec in an innovative way for product recommendations (related blog post).\n",
    "\n",
    "If you tell me about what problem you are trying to solve, may be I can suggest which method will be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 150000/150000 [00:00<00:00, 371142.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 177777.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "# 여기서는 15만개 training documents 전부 사용함\n",
    "cnt = 1000000\n",
    "tagged_train_docs = [TaggedDocument(d, [c]) for d, c in tqdm(train_docs[:cnt])]\n",
    "tagged_test_docs = [TaggedDocument(d, [c]) for d, c in tqdm(test_docs[:cnt])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mac475\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import doc2vec\n",
    "\n",
    "# 사전 구축\n",
    "doc_vectorizer = doc2vec.Doc2Vec(size=300, alpha=0.025, min_alpha=0.025, seed=1234)\n",
    "doc_vectorizer.build_vocab(tagged_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?doc_vectorizer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1871790"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:06<00:58,  6.45s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1872469"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:13<00:52,  6.53s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3743748"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [00:25<01:00,  8.65s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5617265"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:45<01:08, 11.38s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7487437"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:12<01:12, 14.54s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9360677"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:45<01:10, 17.59s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11232239"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [02:25<01:02, 20.84s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13104418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [03:12<00:48, 24.12s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14976882"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [04:08<00:27, 27.64s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16849972"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [05:09<00:00, 30.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train document vectors!\n",
    "for epoch in tqdm(range(10)):\n",
    "    doc_vectorizer.train(tagged_train_docs, epochs=epoch, total_examples=len(tagged_train_docs))\n",
    "    doc_vectorizer.alpha -= 0.002  # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To save\n",
    "doc_vectorizer.save('./model/17.10.15.02.doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('공포영화/Noun', 0.4493910074234009),\n",
       " ('호러/Noun', 0.392019659280777),\n",
       " ('서스펜스/Noun', 0.38125309348106384),\n",
       " ('미스터리/Noun', 0.3314100503921509),\n",
       " ('스릴러/Noun', 0.3085022568702698),\n",
       " ('긴박/Noun', 0.3073579668998718),\n",
       " ('무섭다/Adjective', 0.3045444190502167),\n",
       " ('당혹/Noun', 0.2915957570075989),\n",
       " ('귀신/Noun', 0.29066091775894165),\n",
       " ('박진/Noun', 0.28867214918136597)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('ㅋㅋㄱ/KoreanParticle', 0.2807654142379761),\n",
       " ('빵/Noun', 0.26301223039627075),\n",
       " ('-_-;/Punctuation', 0.24678769707679749),\n",
       " ('~~~!!!/Punctuation', 0.24049502611160278),\n",
       " ('왤다/Verb', 0.24032855033874512),\n",
       " ('ㅉㅉ/KoreanParticle', 0.23816987872123718),\n",
       " ('ㅋ/KoreanParticle', 0.23777486383914948),\n",
       " ('개잼/Noun', 0.22892747819423676),\n",
       " ('빵빵/Noun', 0.2283269762992859),\n",
       " ('두준/Noun', 0.22832536697387695)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.most_similar('공포/Noun')\n",
    "\n",
    "doc_vectorizer.most_similar('ㅋㅋ/KoreanParticle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['아/Exclamation', '더빙/Noun', '../Punctuation', '진짜/Noun', '짜증/Noun', '나다/Verb', '목소리/Noun'], tags=['0'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_train_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('압/Noun', 0.2658236622810364),\n",
       " ('증인/Noun', 0.24955277144908905),\n",
       " ('구혜선/Noun', 0.24669775366783142),\n",
       " ('크리스틴/Noun', 0.24441316723823547),\n",
       " ('총집/Noun', 0.23989495635032654),\n",
       " ('조정석/Noun', 0.23231792449951172),\n",
       " ('심은경/Noun', 0.2314663529396057),\n",
       " ('김정일/Noun', 0.23072248697280884),\n",
       " ('연기대상/Noun', 0.229667529463768),\n",
       " ('더욱더/Noun', 0.22628194093704224)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.most_similar(positive=['여자/Noun', '왕/Noun'], negative=['남자/Noun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_vectorizer.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test = '여자/Noun 왕/Noun'.split()\n",
    "\n",
    "new_vector = doc_vectorizer.infer_vector(tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?doc_vectorizer.docvecs.most_similar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 0.17736783623695374), ('1', 0.1082363873720169)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.docvecs.most_similar([new_vector]) #gives you top 10 document tags and their cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 다음은 이것을 확인할 것\n",
    "\n",
    "# https://www.lucypark.kr/courses/2015-ba/text-mining.html#3-load-tokens-with-nltktext"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
